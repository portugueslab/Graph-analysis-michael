{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have run the first notebook for the registration (**1_antspy_morphing_windows.ipynb**), we can proceed to the ANTsPy registration. <br>\n",
    "You should be running this notebook in your Linux subsystem, and have already uploaded the files your generated in the first notebook.\n",
    "\n",
    "You can find the source code for **ANTsPy** [here](https://github.com/ANTsX/ANTsPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import ants\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import ants_tools as utilities\n",
    "\n",
    "from skimage.exposure import match_histograms\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "from ipywidgets import widgets\n",
    "\n",
    "from quickdisplay import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING STACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/otprat/velos_data/210722_f5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = list(Path(r'/home/otprat/velos_data').glob('*_f*'))\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_path = path_list[0]\n",
    "print('Working on {}'.format(fish_path.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_dir = fish_path #Path to where you uploaded the files generated in the windows notebook\n",
    "\n",
    "#Load stacks\n",
    "ref_stack = fl.load(registration_dir / \"ref_mapped.h5\")\n",
    "mov_stack = fl.load(registration_dir / \"mov_mapped.h5\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform first some histogram scaling and matching.<br>\n",
    "This can generally make the registration process a bit easier, but one should inspect the stack to make sure that the brighter regions are similar between the two stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale brightness\n",
    "ref_stack = to_255_range(ref_stack, quantile_max=0.9999)\n",
    "mov_stack = to_255_range(mov_stack, quantile_min=0.01, quantile_max=0.9999)\n",
    "\n",
    "#Histogram matching\n",
    "ref_stack = match_histograms(ref_stack, mov_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0519ce0c581b4cf3bcb75aa227fd599d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='depth', step=5), Output()), _do…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function quickdisplay.plot_side_to_side(stack1, stack2, depth, dim, stack1_title='Stack 1', stack2_title='Stack 2')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_side_to_side,\n",
    "        stack1=fixed(ref_stack),\n",
    "        stack2=fixed(mov_stack),\n",
    "        depth = widgets.IntSlider(min=0, max=100, step=5, continuous_update=False),\n",
    "        dim = fixed(2),\n",
    "        stack1_title=fixed('Ref stack'),\n",
    "        stack2_title=fixed('Functional stack'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGISTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to AntsPy image format\n",
    "ref_img = ants.from_numpy(ref_stack).clone(\"float\")\n",
    "mov_img = ants.from_numpy(mov_stack).clone(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import an initial transformation matrix to help improve the result from the registration. If you don't have such matrix, go back to the Windows notebook, and run it to do some initial manual alignment. <br>\n",
    "It is not essential, but definitely useful. If you want to skip this step, make sure to remove the `initial_transform` argument when calling the `ants.registration` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the initial transormation matrix (found with the manual annotations) to ANTs format\n",
    "transform_mat = fl.load(registration_dir / \"initial_transform_mapped.h5\")\n",
    "path_initial = str(registration_dir / \"initial_transform_mapped.mat\")\n",
    "at = ants.create_ants_transform(transform_type='AffineTransform', precision='float', dimension=3,\n",
    "                                matrix=transform_mat[:, :3], offset=transform_mat[:, 3])\n",
    "ants.write_transform(at, path_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform the registration. \n",
    "\n",
    "I generally like to perform first a nice affine transformation that morphs the two stacks as well as possible, and then play around with the parameters for the deformation. For a high quality affine mapping, the `'TRSAA'` transformation type is very suitable, and then the diffeomorphic transformation can be done via `'SyNOnly'` transforms that only introduce deformations. However, one can also apply both transformations simultaneously via a `'SyNRA'` transformation.  <br> Doing this process in a single or multiple steps will affect how the transformations need to be applied later on to coordinates in order to transform single point locations. For more information on that topic, check the tutorial [here](https://github.com/ANTsX/ANTsPy/blob/master/tutorials/concatenateRegistrations.ipynb).\n",
    "\n",
    "Check the [documentation](https://antspy.readthedocs.io/en/latest/registration.html) about `ants.registration` for more information about transformation types and the arguments that they accept.\n",
    "\n",
    "*Note on troubleshooting*: if the regsitration functions returns your reference stack as the mov_out image, it means there is an error in your call of the function. Check the linux terminal to try to find where the issue is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 47s, sys: 10.4 s, total: 12min 57s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "affine_tx = ants.registration(fixed=ref_img, \n",
    "                              moving=mov_img,\n",
    "                              initial_transform=path_initial,\n",
    "                              type_of_transform='TRSAA',\n",
    "                              aff_metric='mattes',\n",
    "                              aff_sampling=1,\n",
    "                              total_sigma=0,\n",
    "                              flow_sigma=0,\n",
    "                              reg_iterations=[20, 15, 10],\n",
    "                              outprefix=str(registration_dir / 'affine_tx_'),\n",
    "                              verbose=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an intermediate step, we can retrieve the morphed image and see how the affine transform performs by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve output image\n",
    "affine_stack = affine_tx['warpedmovout'].numpy()\n",
    "fl.save(registration_dir / '{}_affine.h5'.format(fish_path.name), affine_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbb70862f38493faecfc8ff372b6713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='plane', max=128), Text(value='R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function quickdisplay.plot_overlay(ref, mov, plane, dim, ref_title='Reference', mov_title='Warped movout')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_overlay,\n",
    "         ref=fixed(ref_stack),\n",
    "         mov=fixed(affine_stack),\n",
    "         plane=widgets.IntSlider(min=0, max=ref_stack.shape[2]-1, step=1, continuous_update=False),\n",
    "         dim = fixed(2),\n",
    "         stack1_title=fixed('Reference'),\n",
    "         stack2_title=fixed('Affine movout'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffeomorphic registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can proceed with the diffeomorphic transformation. This time, when calling the morphing function, we will use the `SyNOnly` method, which performs only a deformation transformation, and we will specify as the initial transformation, the resulting affine derived in the previous step. <br>\n",
    "Moreover, especially with these defomative tranformations, we want to play around a lot with the other parameters that we are passing to the registration function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_affine_tx = str(next(registration_dir.glob('affine_tx*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 43s, sys: 1min 38s, total: 27min 21s\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warp_tx = ants.registration(fixed=ref_img,\n",
    "                            moving=mov_img,\n",
    "                            initial_transform=initial_affine_tx,\n",
    "                            type_of_transform='SyNOnly',\n",
    "                            syn_sampling=80, \n",
    "                            flow_sigma=10, \n",
    "                            reg_iterations=[15, 10, 5],\n",
    "                            outprefix=str(registration_dir / 'warp_tx_'),\n",
    "                            verbose=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can finally retrieve the registered images and see how well they match the reference stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve output image\n",
    "warp_stack = warp_tx['warpedmovout'].numpy()\n",
    "fl.save(registration_dir / '{}_warp.h5'.format(fish_path.name), warp_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1ab19d97a44911a7cdb8b3402e81f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='plane', max=128), Text(value='R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function quickdisplay.plot_overlay(ref, mov, plane, dim, ref_title='Reference', mov_title='Warped movout')>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_overlay,\n",
    "         ref=fixed(ref_stack),\n",
    "         mov=fixed(warp_stack),\n",
    "         plane=widgets.IntSlider(min=0, max=ref_stack.shape[2]-1, step=1, continuous_update=False),\n",
    "         dim = fixed(2),\n",
    "         stack1_title=fixed('Reference'),\n",
    "         stack2_title=fixed('Warped movout'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffeomorphic transformations can be a bit tricky to get right, as in order to optimize the registration, minimization algorithms can sometimes perform very sharp or radical warpings on our stacks. While these can result in nice registrations, it can also happen that they pick up on small details or artifacts and the registrations become excessively deformed. This is why it is important to tinker with the parameters from the prvious registration function.\n",
    "\n",
    "\n",
    "In order to see how these warp fields deform our stacks, we can look into the Jacobian of the deformations, to get an idea of how each pixel is affected by the deformations. <br>\n",
    "The Jacobian determinant of our deformation matrix provides an idea of how the space around a pixel is deformed as a result of the warping. Values above 1 indicate that the area of neighboring pixels is being stretched, while for values below 1, these areas are being compressed. Below, we plot the log of this determinant.<br>\n",
    "For a nice series on Jacobian matrices, you can check [these videos](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/jacobian-prerequisite-knowledge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_det_mat_log = ants.create_jacobian_determinant_image(ref_img, warp_tx['fwdtransforms'][0], do_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafbbf34ed8c4305aef5350996ea4eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='plane', max=128), Output()), _d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.view_jacobian(ref, mov_affine, mov_warped, jacobian_mat, plane, dim)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(view_jacobian,\n",
    "        ref=fixed(ref_stack),\n",
    "        mov_affine=fixed(affine_stack),\n",
    "        mov_warped=fixed(warp_stack),\n",
    "        jacobian_mat=fixed(jacobian_det_mat_log),\n",
    "        plane=widgets.IntSlider(min=0, max=ref_stack.shape[2]-1, step=1, continuous_update=False),\n",
    "        dim = fixed(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COORDINATE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can import the coordinates for our ROIs and apply those same transformations to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying ANTsPy transformations (whether it is to point coordinates or stacks) one needs to pay attention to the arguments `transformlist` and `whichtoinvert`.\n",
    "\n",
    "- The inputs for `transformlist` you have to pass for each one will depend on the order in which you performed your registrations, as well as on whether your specific registrations are performing different types of registrations simultaneously (i.e., affine + diffeomorphic).\n",
    "\n",
    "- The same goes for the `whichtoinvert` one, which basically points to which of the provided transformations in `transformlist` need to be inverted before being applied (inversion is required for affine transformations, but not for deformations).\n",
    "\n",
    "For more information on how to concatenate transformations, you can check this [tutorial](https://github.com/ANTsX/ANTsPy/blob/master/tutorials/concatenateRegistrations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pointer strings to transforms\n",
    "affine_path = next(registration_dir.glob('warp_tx*Affine*'))\n",
    "warp_path = next(registration_dir.glob('warp_tx*InverseWarp*'))\n",
    "\n",
    "#Prepare antspy transformation function inputs\n",
    "tx_list = list([str(affine_path), str(warp_path)])\n",
    "inversion_list = [True, False]\n",
    "\n",
    "#Load ROI coordinates\n",
    "mov_coords = fl.load(registration_dir / \"mov_roi_coords_mapped.h5\")\n",
    "\n",
    "#Create DataFrame with coordinates to transform\n",
    "mov_coords_df = pd.DataFrame(mov_coords, columns=['x', 'y', 'z'])\n",
    "\n",
    "#Transform ROI coordinates\n",
    "mov_coords_trans = ants.apply_transforms_to_points(3, mov_coords_df, transformlist=tx_list, whichtoinvert=inversion_list).values\n",
    "\n",
    "#Store\n",
    "fl.save(fish_path / 'mov_roi_coords_transformed.h5', mov_coords_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A check to make sure all ROIs are morphed inside the reference brain\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(np.nanmean(ref_stack, 2), cmap='gray')\n",
    "plt.scatter(mov_coords_trans[:, 1], mov_coords_trans[:, 0], c='red', alpha=.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
